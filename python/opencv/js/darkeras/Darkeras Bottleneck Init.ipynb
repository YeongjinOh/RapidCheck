{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.core import Flatten, Dense, Activation, Reshape\n",
    "\n",
    "import tensorflow as tf\n",
    "import yolo.config as cfg\n",
    "from utils.help import say"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.set_image_dim_ordering('th')\n",
    "weights_path = 'yolo-tiny-origin.h5'\n",
    "is_freeze = True\n",
    "verbalise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_yolotiny_network(is_freeze=True):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), input_shape=(3,448,448),padding='same', \n",
    "                            activation=LeakyReLU(alpha=0.1), trainable=not is_freeze))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32,(3,3), padding='same', \n",
    "                            activation=LeakyReLU(alpha=0.1), trainable=not is_freeze))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    model.add(Conv2D(64,(3,3), padding='same', \n",
    "                            activation=LeakyReLU(alpha=0.1), trainable=not is_freeze))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    model.add(Conv2D(128,(3,3), padding='same', \n",
    "                            activation=LeakyReLU(alpha=0.1), trainable=not is_freeze))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    model.add(Conv2D(256,(3,3), padding='same', \n",
    "                            activation=LeakyReLU(alpha=0.1), trainable=not is_freeze))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    model.add(Conv2D(512,(3,3), padding='same', \n",
    "                            activation=LeakyReLU(alpha=0.1), trainable=not is_freeze))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "    model.add(Conv2D(1024,(3,3), padding='same', activation=LeakyReLU(alpha=0.1), trainable=not is_freeze))\n",
    "    model.add(Conv2D(1024,(3,3), padding='same', activation=LeakyReLU(alpha=0.1), trainable=not is_freeze))\n",
    "    model.add(Conv2D(1024,(3,3), padding='same', activation=LeakyReLU(alpha=0.1), trainable=not is_freeze))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(4096))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(1470))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_bottleneck_network(model):\n",
    "    model.add(Dense(256, input_shape=model.output_shape))\n",
    "    model.add(Dense(4096))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(1470))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 448, 448)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 224, 224)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 224, 224)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 112, 112)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 56, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 56, 56)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 128, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 28, 28)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 256, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 512, 14, 14)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1024, 7, 7)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1024, 7, 7)        9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1024, 7, 7)        9438208   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1470)              6022590   \n",
      "=================================================================\n",
      "Total params: 45,089,374\n",
      "Trainable params: 19,920,574\n",
      "Non-trainable params: 25,168,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_yolotiny_network()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yolo.training_v1 import darkeras_loss, _TRAINER\n",
    "from yolo.dataset.data import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Building yolo-tiny loss function']\n",
      "Building yolo-tiny loss\n",
      "['Building yolo-tiny train optimizer']\n",
      "['Setting weigths : {}', 'yolo-tiny-origin.h5']\n",
      "['None layer poped']\n",
      "['None layer poped']\n",
      "['None layer poped']\n",
      "['None layer poped']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 448, 448)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 224, 224)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 224, 224)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 112, 112)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 56, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 56, 56)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 128, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 28, 28)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 256, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 512, 14, 14)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1024, 7, 7)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1024, 7, 7)        9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1024, 7, 7)        9438208   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "=================================================================\n",
      "Total params: 25,168,800\n",
      "Trainable params: 0\n",
      "Non-trainable params: 25,168,800\n",
      "_________________________________________________________________\n",
      "(None, 50176)\n"
     ]
    }
   ],
   "source": [
    "inp_x = model.input\n",
    "net_out = model.output\n",
    "sess = K.get_session()\n",
    "\n",
    "say(\"Building {} loss function\".format(cfg.model_name), verbalise=verbalise)\n",
    "loss_ph, loss_op = darkeras_loss(net_out)\n",
    "say(\"Building {} train optimizer\".format(cfg.model_name), verbalise=verbalise)\n",
    "optimizer = _TRAINER[cfg.trainer](cfg.lr)\n",
    "gradients = optimizer.compute_gradients(loss_op)\n",
    "train_op = optimizer.apply_gradients(gradients)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "model.load_weights(weights_path)\n",
    "say(\"Setting weigths : {}\",format(weights_path), verbalise=verbalise)\n",
    "\n",
    "pop_layer = model.pop() # dense_25\n",
    "say(\"{} layer poped\".format(pop_layer), verbalise=verbalise)\n",
    "pop_layer = model.pop() # leakyrelu_34\n",
    "say(\"{} layer poped\".format(pop_layer), verbalise=verbalise)\n",
    "pop_layer = model.pop() # dense_24\n",
    "say(\"{} layer poped\".format(pop_layer), verbalise=verbalise)\n",
    "pop_layer = model.pop() # dense 23\n",
    "say(\"{} layer poped\".format(pop_layer), verbalise=verbalise)\n",
    "\n",
    "model.summary()\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 448, 448)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 224, 224)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 224, 224)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 112, 112)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 56, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 56, 56)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 128, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 28, 28)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 256, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 512, 14, 14)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1024, 7, 7)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1024, 7, 7)        9438208   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1024, 7, 7)        9438208   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1470)              6022590   \n",
      "=================================================================\n",
      "Total params: 45,089,374\n",
      "Trainable params: 19,920,574\n",
      "Non-trainable params: 25,168,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_bottleneck_network(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset of 9963 instance(s)\n",
      "shuffle index :  [  84 2981 3162 ..., 3567 1886 4583]\n",
      "['step 0 - loss 1.830634593963623']\n",
      "['step 1 - loss 2.9135732650756836']\n",
      "Saved weigths :  yolo-tiny-step1.h5\n",
      "['step 2 - loss 1.6306806802749634']\n",
      "['step 3 - loss 1.977710247039795']\n",
      "['step 4 - loss 2.4008426666259766']\n",
      "['step 5 - loss 2.9010069370269775']\n",
      "['step 6 - loss 1.898966908454895']\n",
      "['step 7 - loss 2.4896249771118164']\n",
      "['step 8 - loss 1.9629135131835938']\n",
      "['step 9 - loss 3.87100887298584']\n",
      "['step 10 - loss 1.7466118335723877']\n",
      "['step 11 - loss 3.297980308532715']\n",
      "['step 12 - loss 2.2121381759643555']\n",
      "['step 13 - loss 2.622051239013672']\n",
      "['step 14 - loss 1.8840867280960083']\n",
      "['step 15 - loss 2.4684433937072754']\n",
      "['step 16 - loss 1.9220449924468994']\n",
      "['step 17 - loss 1.8221871852874756']\n",
      "['step 18 - loss 1.88920259475708']\n",
      "['step 19 - loss 2.4026126861572266']\n",
      "['step 20 - loss 2.066751480102539']\n",
      "['step 21 - loss 1.9796459674835205']\n",
      "['step 22 - loss 2.1538681983947754']\n",
      "['step 23 - loss 2.7586636543273926']\n",
      "['step 24 - loss 1.6486151218414307']\n",
      "['step 25 - loss 2.546693801879883']\n",
      "['step 26 - loss 2.8818273544311523']\n",
      "['step 27 - loss 2.031637668609619']\n",
      "['step 28 - loss 1.6714743375778198']\n",
      "['step 29 - loss 1.813490867614746']\n",
      "['step 30 - loss 1.8047086000442505']\n",
      "['step 31 - loss 2.38986873626709']\n",
      "['step 32 - loss 1.8160521984100342']\n",
      "['step 33 - loss 1.7300126552581787']\n",
      "['step 34 - loss 2.3419504165649414']\n",
      "['step 35 - loss 2.1589107513427734']\n",
      "['step 36 - loss 2.333466053009033']\n",
      "['step 37 - loss 1.917531132698059']\n",
      "['step 38 - loss 2.485487937927246']\n",
      "['step 39 - loss 1.9635543823242188']\n",
      "['step 40 - loss 2.8088951110839844']\n",
      "['step 41 - loss 2.7325563430786133']\n",
      "['step 42 - loss 1.8663337230682373']\n",
      "['step 43 - loss 2.2648472785949707']\n",
      "['step 44 - loss 2.086737632751465']\n",
      "['step 45 - loss 1.7324488162994385']\n",
      "['step 46 - loss 3.2676124572753906']\n",
      "['step 47 - loss 1.792195439338684']\n",
      "['step 48 - loss 1.906733512878418']\n",
      "['step 49 - loss 1.935049295425415']\n",
      "['step 50 - loss 2.3311805725097656']\n",
      "['step 51 - loss 1.892466425895691']\n",
      "['step 52 - loss 2.098522424697876']\n",
      "['step 53 - loss 2.614551067352295']\n",
      "['step 54 - loss 1.7677797079086304']\n",
      "['step 55 - loss 1.4291527271270752']\n",
      "['step 56 - loss 1.917292833328247']\n",
      "['step 57 - loss 1.558373212814331']\n",
      "['step 58 - loss 1.7002410888671875']\n",
      "['step 59 - loss 2.771669387817383']\n",
      "['step 60 - loss 2.5610833168029785']\n",
      "['step 61 - loss 1.9691658020019531']\n",
      "['step 62 - loss 1.4447834491729736']\n",
      "['step 63 - loss 1.8271020650863647']\n",
      "['step 64 - loss 1.94215726852417']\n",
      "['step 65 - loss 2.4128975868225098']\n",
      "['step 66 - loss 1.7713690996170044']\n",
      "['step 67 - loss 2.2678980827331543']\n",
      "['step 68 - loss 2.073028087615967']\n",
      "['step 69 - loss 2.081879138946533']\n",
      "['step 70 - loss 1.9111449718475342']\n",
      "['step 71 - loss 1.7528434991836548']\n",
      "['step 72 - loss 1.714256763458252']\n",
      "['step 73 - loss 3.841116189956665']\n",
      "['step 74 - loss 2.2264842987060547']\n",
      "['step 75 - loss 2.0622644424438477']\n",
      "['step 76 - loss 1.8946549892425537']\n",
      "['step 77 - loss 1.8817511796951294']\n",
      "['step 78 - loss 2.316054105758667']\n",
      "['step 79 - loss 1.622844934463501']\n",
      "['step 80 - loss 1.9032442569732666']\n",
      "['step 81 - loss 2.2165324687957764']\n",
      "['step 82 - loss 1.9652283191680908']\n",
      "['step 83 - loss 2.726102352142334']\n",
      "['step 84 - loss 2.668677568435669']\n",
      "['step 85 - loss 2.3451733589172363']\n",
      "['step 86 - loss 2.694214344024658']\n",
      "['step 87 - loss 2.4472169876098633']\n",
      "['step 88 - loss 2.2883002758026123']\n",
      "['step 89 - loss 1.7819379568099976']\n",
      "['step 90 - loss 1.4346590042114258']\n",
      "['step 91 - loss 2.3706507682800293']\n",
      "['step 92 - loss 2.322139263153076']\n",
      "['step 93 - loss 1.6110308170318604']\n",
      "['step 94 - loss 2.3593392372131348']\n",
      "['step 95 - loss 2.8432295322418213']\n",
      "['step 96 - loss 1.6382708549499512']\n",
      "['step 97 - loss 2.177902936935425']\n",
      "['step 98 - loss 1.8979227542877197']\n",
      "['step 99 - loss 1.8428122997283936']\n",
      "['step 100 - loss 1.6653376817703247']\n",
      "['step 101 - loss 2.174680709838867']\n",
      "['step 102 - loss 1.9999703168869019']\n",
      "['step 103 - loss 2.321953773498535']\n",
      "['step 104 - loss 2.3224215507507324']\n",
      "['step 105 - loss 1.888949990272522']\n",
      "['step 106 - loss 1.8454101085662842']\n",
      "['step 107 - loss 2.8253114223480225']\n",
      "['step 108 - loss 2.342665195465088']\n",
      "['step 109 - loss 2.349091053009033']\n",
      "['step 110 - loss 2.7042555809020996']\n",
      "['step 111 - loss 1.7359976768493652']\n",
      "['step 112 - loss 2.4036357402801514']\n",
      "['step 113 - loss 2.4099066257476807']\n",
      "['step 114 - loss 2.066073417663574']\n",
      "['step 115 - loss 2.0541834831237793']\n",
      "['step 116 - loss 2.7116827964782715']\n",
      "['step 117 - loss 2.3906733989715576']\n",
      "['step 118 - loss 1.7921676635742188']\n",
      "['step 119 - loss 1.5270408391952515']\n",
      "['step 120 - loss 1.9766262769699097']\n",
      "['step 121 - loss 2.893404960632324']\n",
      "['step 122 - loss 1.5795929431915283']\n",
      "['step 123 - loss 1.1449682712554932']\n",
      "['step 124 - loss 2.1871886253356934']\n",
      "['step 125 - loss 2.274340867996216']\n",
      "['step 126 - loss 2.2579026222229004']\n",
      "['step 127 - loss 2.322094440460205']\n",
      "['step 128 - loss 1.9934496879577637']\n",
      "['step 129 - loss 2.2071874141693115']\n",
      "['step 130 - loss 2.475738763809204']\n",
      "['step 131 - loss 1.7452805042266846']\n",
      "['step 132 - loss 2.0469064712524414']\n",
      "['step 133 - loss 2.742431163787842']\n",
      "['step 134 - loss 2.4207241535186768']\n",
      "['step 135 - loss 2.9013142585754395']\n",
      "['step 136 - loss 2.056351661682129']\n",
      "['step 137 - loss 2.6006927490234375']\n",
      "['step 138 - loss 1.9153918027877808']\n",
      "['step 139 - loss 2.2268080711364746']\n",
      "['step 140 - loss 2.336483955383301']\n",
      "['step 141 - loss 1.927416205406189']\n",
      "['step 142 - loss 1.6311079263687134']\n",
      "['step 143 - loss 1.8127915859222412']\n",
      "['step 144 - loss 1.588892936706543']\n",
      "['step 145 - loss 1.794556975364685']\n",
      "['step 146 - loss 2.1945650577545166']\n",
      "['step 147 - loss 2.310347557067871']\n",
      "['step 148 - loss 2.562008857727051']\n",
      "['step 149 - loss 1.6700143814086914']\n",
      "['step 150 - loss 3.1943140029907227']\n",
      "['step 151 - loss 2.224191427230835']\n",
      "['step 152 - loss 2.4234042167663574']\n",
      "['step 153 - loss 1.8487365245819092']\n",
      "['step 154 - loss 1.7914552688598633']\n",
      "['step 155 - loss 1.4866636991500854']\n",
      "['step 156 - loss 2.1340980529785156']\n",
      "['step 157 - loss 1.3299565315246582']\n",
      "['step 158 - loss 2.484729051589966']\n",
      "['step 159 - loss 1.6857326030731201']\n",
      "['step 160 - loss 2.789675235748291']\n",
      "['step 161 - loss 1.826587200164795']\n",
      "['step 162 - loss 2.281536817550659']\n",
      "['step 163 - loss 1.950871467590332']\n",
      "['step 164 - loss 1.3388080596923828']\n",
      "['step 165 - loss 1.7760083675384521']\n",
      "['step 166 - loss 2.5178980827331543']\n",
      "['step 167 - loss 2.2048234939575195']\n",
      "['step 168 - loss 1.3834202289581299']\n",
      "['step 169 - loss 2.425487995147705']\n",
      "['step 170 - loss 1.7930819988250732']\n",
      "['step 171 - loss 1.6273865699768066']\n",
      "['step 172 - loss 2.595064163208008']\n",
      "['step 173 - loss 1.8592514991760254']\n",
      "['step 174 - loss 2.205380439758301']\n",
      "['step 175 - loss 1.9233328104019165']\n",
      "['step 176 - loss 1.9118350744247437']\n",
      "['step 177 - loss 2.0057008266448975']\n",
      "['step 178 - loss 2.1089999675750732']\n",
      "['step 179 - loss 1.8722071647644043']\n",
      "['step 180 - loss 1.9333714246749878']\n",
      "['step 181 - loss 1.7491044998168945']\n",
      "['step 182 - loss 2.10261607170105']\n",
      "['step 183 - loss 1.9452896118164062']\n",
      "['step 184 - loss 2.297619342803955']\n",
      "['step 185 - loss 2.3125619888305664']\n",
      "['step 186 - loss 2.06990647315979']\n",
      "['step 187 - loss 1.4879976511001587']\n",
      "['step 188 - loss 1.8591424226760864']\n",
      "['step 189 - loss 2.1332006454467773']\n",
      "['step 190 - loss 2.238281726837158']\n",
      "['step 191 - loss 2.817577362060547']\n",
      "['step 192 - loss 1.0996092557907104']\n",
      "['step 193 - loss 2.1230812072753906']\n",
      "['step 194 - loss 1.8185889720916748']\n",
      "['step 195 - loss 1.6656208038330078']\n",
      "['step 196 - loss 2.2078094482421875']\n",
      "['step 197 - loss 2.70347261428833']\n",
      "['step 198 - loss 2.3132035732269287']\n",
      "['step 199 - loss 1.67570960521698']\n",
      "['step 200 - loss 2.018843650817871']\n",
      "['step 201 - loss 1.9880061149597168']\n",
      "['step 202 - loss 2.1587419509887695']\n",
      "['step 203 - loss 2.313197374343872']\n",
      "['step 204 - loss 2.539191246032715']\n",
      "['step 205 - loss 1.3919520378112793']\n",
      "['step 206 - loss 2.4961578845977783']\n",
      "['step 207 - loss 1.9292906522750854']\n",
      "['step 208 - loss 1.2761280536651611']\n",
      "['step 209 - loss 1.8816266059875488']\n",
      "['step 210 - loss 2.1416001319885254']\n",
      "['step 211 - loss 2.435305595397949']\n",
      "['step 212 - loss 1.7405024766921997']\n",
      "['step 213 - loss 2.1698694229125977']\n",
      "['step 214 - loss 2.0975522994995117']\n",
      "['step 215 - loss 1.9251594543457031']\n",
      "['step 216 - loss 2.166558265686035']\n",
      "['step 217 - loss 1.534885048866272']\n",
      "['step 218 - loss 1.8260856866836548']\n",
      "['step 219 - loss 1.4365863800048828']\n",
      "['step 220 - loss 2.177574634552002']\n",
      "['step 221 - loss 1.8408050537109375']\n",
      "['step 222 - loss 2.2565417289733887']\n",
      "['step 223 - loss 2.0556631088256836']\n",
      "['step 224 - loss 2.3337361812591553']\n",
      "['step 225 - loss 2.001034736633301']\n",
      "['step 226 - loss 1.8678735494613647']\n",
      "['step 227 - loss 1.9964256286621094']\n",
      "['step 228 - loss 2.248720169067383']\n",
      "['step 229 - loss 1.8231480121612549']\n",
      "['step 230 - loss 2.4059605598449707']\n",
      "['step 231 - loss 1.9878939390182495']\n",
      "['step 232 - loss 2.406355381011963']\n",
      "['step 233 - loss 2.321268081665039']\n",
      "['step 234 - loss 2.5639023780822754']\n",
      "['step 235 - loss 1.8939766883850098']\n",
      "['step 236 - loss 1.892324447631836']\n",
      "['step 237 - loss 2.175870895385742']\n",
      "['step 238 - loss 3.0260000228881836']\n",
      "['step 239 - loss 2.388092517852783']\n",
      "['step 240 - loss 2.6514735221862793']\n",
      "['step 241 - loss 2.1582305431365967']\n",
      "['step 242 - loss 1.7984906435012817']\n",
      "['step 243 - loss 2.518850803375244']\n",
      "['step 244 - loss 1.8113868236541748']\n",
      "['step 245 - loss 2.2460765838623047']\n",
      "['step 246 - loss 2.696699619293213']\n",
      "['step 247 - loss 2.3266725540161133']\n",
      "['step 248 - loss 1.5351148843765259']\n",
      "['step 249 - loss 1.9953827857971191']\n",
      "['step 250 - loss 2.5369009971618652']\n",
      "['step 251 - loss 2.179049015045166']\n",
      "['step 252 - loss 2.2766828536987305']\n",
      "['step 253 - loss 2.6325812339782715']\n",
      "['step 254 - loss 1.681908130645752']\n",
      "['step 255 - loss 2.104508399963379']\n",
      "['step 256 - loss 2.0949769020080566']\n",
      "['step 257 - loss 2.158137798309326']\n",
      "['step 258 - loss 2.520852565765381']\n",
      "['step 259 - loss 1.4178268909454346']\n",
      "['step 260 - loss 1.5608000755310059']\n",
      "['step 261 - loss 2.0594441890716553']\n",
      "['step 262 - loss 1.665876865386963']\n",
      "['step 263 - loss 1.6773037910461426']\n",
      "['step 264 - loss 2.1977338790893555']\n",
      "['step 265 - loss 2.196218490600586']\n",
      "['step 266 - loss 1.7776570320129395']\n",
      "['step 267 - loss 1.8309659957885742']\n",
      "['step 268 - loss 2.015395164489746']\n",
      "['step 269 - loss 2.1618337631225586']\n",
      "['step 270 - loss 1.9708808660507202']\n",
      "['step 271 - loss 1.4130874872207642']\n",
      "['step 272 - loss 1.8719815015792847']\n",
      "['step 273 - loss 1.9356317520141602']\n",
      "['step 274 - loss 2.1089229583740234']\n",
      "['step 275 - loss 1.9171159267425537']\n",
      "['step 276 - loss 1.8983856439590454']\n",
      "['step 277 - loss 1.9483797550201416']\n",
      "['step 278 - loss 2.0233211517333984']\n",
      "['step 279 - loss 2.0367162227630615']\n",
      "['step 280 - loss 1.7521735429763794']\n",
      "['step 281 - loss 2.193397283554077']\n",
      "['step 282 - loss 2.079989194869995']\n",
      "['step 283 - loss 2.262336492538452']\n",
      "['step 284 - loss 2.123826026916504']\n",
      "['step 285 - loss 2.4935286045074463']\n",
      "['step 286 - loss 2.3392436504364014']\n",
      "['step 287 - loss 1.7405807971954346']\n",
      "['step 288 - loss 2.4731500148773193']\n",
      "['step 289 - loss 1.88033127784729']\n",
      "['step 290 - loss 1.5060360431671143']\n",
      "['step 291 - loss 1.4060803651809692']\n",
      "['step 292 - loss 1.6197105646133423']\n",
      "['step 293 - loss 2.511577844619751']\n",
      "['step 294 - loss 2.6799376010894775']\n",
      "['step 295 - loss 2.3525900840759277']\n",
      "['step 296 - loss 1.6653307676315308']\n",
      "['step 297 - loss 1.4694100618362427']\n",
      "['step 298 - loss 1.7564268112182617']\n",
      "['step 299 - loss 2.3572945594787598']\n",
      "['step 300 - loss 2.460103750228882']\n",
      "['step 301 - loss 2.174365520477295']\n",
      "['step 302 - loss 1.9926215410232544']\n",
      "['step 303 - loss 1.831203579902649']\n",
      "['step 304 - loss 2.5558314323425293']\n",
      "['step 305 - loss 1.8820831775665283']\n",
      "['step 306 - loss 1.8723101615905762']\n",
      "['step 307 - loss 1.8493479490280151']\n",
      "['step 308 - loss 2.1511807441711426']\n",
      "['step 309 - loss 1.5618672370910645']\n",
      "['step 310 - loss 1.6788020133972168']\n",
      "Finish 1 epoch\n",
      "shuffle index :  [1793 4068  720 ...,  688 8136 5032]\n",
      "['step 311 - loss 2.3671164512634277']\n",
      "['step 312 - loss 1.671219825744629']\n",
      "['step 313 - loss 1.855597972869873']\n",
      "['step 314 - loss 2.6232810020446777']\n",
      "['step 315 - loss 1.6640663146972656']\n",
      "['step 316 - loss 1.984614610671997']\n",
      "['step 317 - loss 2.2669084072113037']\n",
      "['step 318 - loss 1.7273106575012207']\n",
      "['step 319 - loss 2.112342596054077']\n",
      "['step 320 - loss 1.9687455892562866']\n",
      "['step 321 - loss 2.157609462738037']\n",
      "['step 322 - loss 1.9087975025177002']\n",
      "['step 323 - loss 1.8822450637817383']\n",
      "['step 324 - loss 1.390950083732605']\n",
      "['step 325 - loss 2.0075201988220215']\n",
      "['step 326 - loss 2.098698377609253']\n",
      "['step 327 - loss 1.6543636322021484']\n",
      "['step 328 - loss 2.3564605712890625']\n",
      "['step 329 - loss 2.5898613929748535']\n",
      "['step 330 - loss 2.387479782104492']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7191a5bbe8c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# print(\"feed_dict.keys() : \", len(train_feed_dict.keys()), train_feed_dict.keys())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_feed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SoMa\\Anaconda3\\envs\\venvJupyter\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SoMa\\Anaconda3\\envs\\venvJupyter\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SoMa\\Anaconda3\\envs\\venvJupyter\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\SoMa\\Anaconda3\\envs\\venvJupyter\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SoMa\\Anaconda3\\envs\\venvJupyter\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batches = shuffle()\n",
    "for i, (x_batch, datum) in enumerate(batches):\n",
    "    train_feed_dict = {\n",
    "       loss_ph[key]:datum[key] for key in loss_ph \n",
    "    }\n",
    "    train_feed_dict[inp_x] = x_batch\n",
    "    # print(\"feed_dict.keys() : \", len(train_feed_dict.keys()), train_feed_dict.keys())\n",
    "    fetches = [train_op, loss_op] \n",
    "    fetched = sess.run(fetches, feed_dict=train_feed_dict)\n",
    "    \n",
    "    loss_val = fetched[1]\n",
    "    say(\"step {} - loss {}\".format(i, loss_val), verbalise=True)\n",
    "    if i == 1:\n",
    "        save_step_weigths_path = 'yolo-tiny-step{}.h5'.format(i)\n",
    "        model.save_weights(save_step_weigths_path)\n",
    "        print(\"Saved weigths : \", save_step_weigths_path)\n",
    "    if i % 310 == 0:\n",
    "        model.save_weights('yolo-tiny-epoch{}.h5'.format(i//310))\n",
    "        say(\"Save weights : \", 'yolo-tiny-epoch{}.h5'.format(i//310), verbalise=verbalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convolution2d_1\n",
      "convolution2d_1/convolution2d_1_W:0\n",
      "convolution2d_1/convolution2d_1_b:0\n",
      "convolution2d_2\n",
      "convolution2d_2/convolution2d_2_W:0\n",
      "convolution2d_2/convolution2d_2_b:0\n",
      "convolution2d_3\n",
      "convolution2d_3/convolution2d_3_W:0\n",
      "convolution2d_3/convolution2d_3_b:0\n",
      "convolution2d_4\n",
      "convolution2d_4/convolution2d_4_W:0\n",
      "convolution2d_4/convolution2d_4_b:0\n",
      "convolution2d_5\n",
      "convolution2d_5/convolution2d_5_W:0\n",
      "convolution2d_5/convolution2d_5_b:0\n",
      "convolution2d_6\n",
      "convolution2d_6/convolution2d_6_W:0\n",
      "convolution2d_6/convolution2d_6_b:0\n",
      "convolution2d_7\n",
      "convolution2d_7/convolution2d_7_W:0\n",
      "convolution2d_7/convolution2d_7_b:0\n",
      "convolution2d_8\n",
      "convolution2d_8/convolution2d_8_W:0\n",
      "convolution2d_8/convolution2d_8_b:0\n",
      "convolution2d_9\n",
      "convolution2d_9/convolution2d_9_W:0\n",
      "convolution2d_9/convolution2d_9_b:0\n",
      "dense_1\n",
      "dense_1/dense_1_W:0\n",
      "dense_1/dense_1_b:0\n",
      "dense_2\n",
      "dense_2/dense_2_W:0\n",
      "dense_2/dense_2_b:0\n",
      "dense_3\n",
      "dense_3/dense_3_W:0\n",
      "dense_3/dense_3_b:0\n",
      "flatten_1\n",
      "leakyrelu_10\n",
      "maxpooling2d_1\n",
      "maxpooling2d_2\n",
      "maxpooling2d_3\n",
      "maxpooling2d_4\n",
      "maxpooling2d_5\n",
      "maxpooling2d_6\n"
     ]
    }
   ],
   "source": [
    "def printname(name):\n",
    "    print(name)\n",
    "\n",
    "f = h5py.File(weights_path)\n",
    "f.visit(printname)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
